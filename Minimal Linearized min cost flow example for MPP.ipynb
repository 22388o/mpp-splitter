{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a minimalistic demonstration to transform the [minimum convex cost problem to find the most likely payment flow on the Lightning network](https://arxiv.org/abs/2107.05322) to a linearized problem that can be solved in sub second time on the current channel graph with the help of a [linear min cost flow solver](https://developers.google.com/optimization/reference/graph/min_cost_flow). \n",
    "\n",
    "## Idea\n",
    "Using the ideas of [probabilistic payment delivery](https://arxiv.org/abs/2103.08576) (sometimes known as probabilistic path finding) which has been already [implemented](https://github.com/ElementsProject/lightning/pull/4771) and [tested by c-lightning](https://medium.com/blockstream/c-lightning-v0-10-2-bitcoin-dust-consensus-rule-33e777d58657) as well as [implemented by LDK](https://github.com/lightningdevkit/rust-lightning/pull/1227) (aka rust lightning) we know that the cost function to assign to assign the amount $a$ to a channel of capacity $c$ to use when selecting channels should be \n",
    "\n",
    "$f_c(a) = -\\log\\left(\\frac{c+1-a}{c+1}\\right)$ \n",
    "\n",
    "The linear approximation of this cost function can be found by looking at the first term of the Taylor Series which turns out to be: \n",
    "\n",
    "$l_c(a) = \\frac{a}{c}$\n",
    "\n",
    "The linearized term is easy to compute and interprete: The cost is 0 if not used and 1 if fully saturated and otherwise just proportional to the fraction of saturation. However just using the linearized version yields two problems: \n",
    "\n",
    "1. the unit cost $\\frac{1}{c}$ is a float and not an integer (**making it hard for many mcf solving algorithms**!)\n",
    "2. The linear nature of the problem (like the linear feerate) tends to fully saturate cheap paths which from a reliablity perspective is a very poor choice as fully saturated channels have the lowest probability to be successfull.\n",
    "\n",
    "To mitigate the first problem with floating values as unit costs we multiply all unit costs with the maximum capacity of the network. So with $C_{max}$ as the max capacity. This will just be a linear scaling of the global cost function and thus not change the solution that minimizes the the cost. The function will look like: \n",
    "\n",
    "$L_c(a) = a\\cdot\\lfloor\\frac{C_{max}}{c}\\rfloor$\n",
    "\n",
    "\n",
    "To mitigate the second problem instead of using the same cost function on the entire channel we split the channel in $N$ sements (in our case of equal size to proof a point about runtime. (From an approximation perspective one might want to use the optimal piecewise linear approximation which can also be found via: http://www.iaeng.org/publication/WCECS2008/WCECS2008_pp1191-1194.pdf). So when building the linear approximation of the **uncertainty network** instead of adding one channel with capacity $c$ for each channel we add $N$ channels each of capacity $\\frac{c}{N}$. The unit cost of the i-th channel increases via the following formula: \n",
    "\n",
    "$L_{c,i}(a) = L_{c}(a)\\cdot(i+1)$\n",
    "\n",
    "### Motivation of this choice for the cost function on the piecewise linear segments\n",
    "When using a linear min cost flow solver the unit cost can be seen as the derrivative of the cost function. with the formular $L_{c,i}(a) = L_{c}(a)\\cdot(i+1)$ the unit cost is linearly increasing of every interval of the channel. This effectively behaves like piecewise approximation of a quadratic cost function. \n",
    "\n",
    "Of course in practise one would approximate the derrivative of the negative log probabilities at the positions where the intervals are being created and also not use intervals of equal size.\n",
    "\n",
    "As this code is to demonstrate feasability of runtime (the linearized model of the **uncertainty network** on which we calculates has $N$ times as many edges as the convex problem) this very pragmatic and easy to implement choice will be good enough.\n",
    "\n",
    "\n",
    "## Warning: This code DOES NOT \n",
    "* include optimization for routing fees (in the case of prallel channels it does not even account the paid fees properly)\n",
    "* include the round based algorithm on the uncertainty network which learns conditional probabilities from attempted onions\n",
    "* include the disection of the flow into paths (which is conceptionally straight forward)\n",
    "* care for HTLCs limits, channel reserves and the like (as all of that is more engineering level)\n",
    "* Use the optimal piecewise linear approximation for the convex cost function (as described here: http://www.iaeng.org/publication/WCECS2008/WCECS2008_pp1191-1194.pdf) \n",
    "* properly handle parallel public channels (actually it just virtually combines the capacity which from a probabilistic perspective makes a hell lot of sense)\n",
    "* include a simluation of the round based algorithm\n",
    "* make any mainnet test payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "#using googles linear min cost flow solver as and externaly for convenience.\n",
    "# it seems to use a cost scaling algorithm internally find more information \n",
    "# on their API doc at:  https://developers.google.com/optimization/reference/graph/min_cost_flow\n",
    "from ortools.graph import pywrapgraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set a few global variables. Global because our entire code is basically one script with not even 100 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to map node_ids to the range [0,...,#number of nodes] and vice versa\n",
    "node_key_to_id = {}\n",
    "id_to_node_key = {}\n",
    "\n",
    "\n",
    "#the will become the list of arcs that are actually stored in the \n",
    "arcs = []\n",
    "\n",
    "#used to store the capacity of channels\n",
    "channel_graph = {}\n",
    "\n",
    "#used to store fees as a touple (base_fee_msat,ppm)\n",
    "fee_graph = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set a few parameters for the experiment some of these numbers might heavily impact runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantizing payments sets a lower bound on sent HTLCs and speeds up the computation a bit\n",
    "#set this to 1 if it is to be turned off\n",
    "QUANTIZATION = 10000\n",
    "\n",
    "#renes node\n",
    "SRC = \"03efccf2c383d7bf340da9a3f02e2c23104a0e4fe8ac1a880c8e2dc92fbdacd9df\"\n",
    "#loop node\n",
    "DEST = \"021c97a90a411ff2b10dc2a8e32de2f29d2fa49d41bfbb52bd416e460db0747d0d\"\n",
    "AMT = 10*1000*1000 #1 Bitcoin\n",
    "#number of piecewise linear approximations. Increasing this directly increases runtime but also improves accuracy\n",
    "N = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define two helper functions for depicting results. We want to be able to compute the actual probability of the flow and we want to also be able to know what the flow (if fully successfull) would cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_probability(a,s,d):\n",
    "    \"\"\"\n",
    "    Computes the uniform probablity of a payment of amout `a` on a channel s-->d\n",
    "    \"\"\"\n",
    "    c = channel_graph[s][d]\n",
    "    return float(c+1-a)/(c+1)\n",
    "\n",
    "def fee_msat(a,s,d):\n",
    "    \"\"\"\n",
    "    Computes the the fees of a payment of amout `a` on a channel s-->d\n",
    "    \"\"\"\n",
    "    base, rate = fee_graph[s][d]\n",
    "    # note we divide ppm by 1000 to be compatible with base_fee wich is measured in msat and not sats\n",
    "    return base + a*rate/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max capacity is:  1400000000\n"
     ]
    }
   ],
   "source": [
    "def import_channels():\n",
    "    \"\"\"\n",
    "    this does all the magic! it imports the channel_graph from c-lightning listchannels command\n",
    "    \n",
    "    it first passes through the channels to find all node ids and max capacity\n",
    "    in a second pass it goes over all channels and adds arcs to the modelled linearized network\n",
    "    for each channel N arcs are being added with increasing unit costs to mimick convex behavior\n",
    "    the piecewise dissection is not optimal nor is the linear approximation of negative log probs exact\n",
    "    however this does not matter for the sake of argument the runtime will not change if the costs\n",
    "    are chosen abit bit more optimally. But the code will blow up thus those simplifications\n",
    "    \"\"\"\n",
    "    f = open(\"listchannels20211028.json\")\n",
    "    channels = json.load(f)[\"channels\"]\n",
    "\n",
    "    #let's first find the max channel capacity and all node_ids \n",
    "    # so that we can build the look up table and use integer unit costs\n",
    "    max_cap = 0\n",
    "    node_ids = set()\n",
    "    for c in channels:\n",
    "        #print(c)\n",
    "        #return\n",
    "        src = c[\"source\"]\n",
    "        dest = c[\"destination\"]\n",
    "        node_ids.add(src)\n",
    "        node_ids.add(dest)\n",
    "        cap = c[\"satoshis\"]\n",
    "        u = 1.0/cap\n",
    "        if cap>max_cap:\n",
    "            max_cap = cap\n",
    "    \n",
    "    print(\"Max capacity is: \", max_cap)\n",
    "    \n",
    "    # let's initialize the look up tables for node_ids to integers from [0,...,#number of nodes]\n",
    "    for k, node_id in enumerate(node_ids):\n",
    "        node_key_to_id[node_id]=k\n",
    "        id_to_node_key[k]=node_id\n",
    "\n",
    "    \n",
    "    # initilize global channel_graph and fee_graph data structures \n",
    "    global channel_graph\n",
    "    channel_graph={node_key_to_id[n]:{} for n in node_ids}\n",
    "    global fee_graph\n",
    "    fee_graph={node_key_to_id[n]:{} for n in node_ids}\n",
    "\n",
    "    #max_cap = 100*max_cap\n",
    "    global arcs\n",
    "    arcs = []\n",
    "    for c in channels:\n",
    "        src = node_key_to_id[c[\"source\"]]\n",
    "        dest = node_key_to_id[c[\"destination\"]]\n",
    "        cap = c[\"satoshis\"]\n",
    "        \n",
    "        # we put channels into channel_Graph data structure\n",
    "        # in case of parallel channels we combine capacity into 1 channel\n",
    "        # from a probabilistic point of view (which we are interested in) this is correct\n",
    "        if dest in channel_graph[src]:\n",
    "            channel_graph[src][dest]+=cap\n",
    "        else:\n",
    "            channel_graph[src][dest]=cap\n",
    "            \n",
    "        # FIXME: this ignores fees of paralel channels. Ok for us as this is not our main concern\n",
    "        fee_graph[src][dest] = (c[\"base_fee_millisatoshi\"],c[\"fee_per_millionth\"])\n",
    "\n",
    "        unit_cost = int(max_cap/cap)\n",
    "        #recall: N is the number of piecewise linear approximations of our cost function\n",
    "        #FIXME: use optimal linear approximation e.g.: http://www.iaeng.org/publication/WCECS2008/WCECS2008_pp1191-1194.pdf\n",
    "        # so for each channel we add N arcs with c/N capacity and increasing unit cost to mimick convex nature\n",
    "        for i in range(N):\n",
    "            #arc format is src, dest, capacity, unit_cost\n",
    "            # THIS IS THE IMPORTANT LINE OF CODE WHERE THE MAGIC HAPPENS\n",
    "            arcs.append((src,dest,int(cap/(N*QUANTIZATION)),(i+1)*unit_cost))\n",
    "\n",
    "import_channels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the min cost flow solver\n",
    "now that we have created the model of the linearized uncertainty network we have to plug this into a linear min cost flow solver. the following code is basically and adoption of the example at google operation research API doc which can be found at https://developers.google.com/optimization/flow/mincostflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deliver 0.10 BTC from 7899 to 952\n",
      "Runtime of flow computation: 0.75 sec \n",
      "Minimum approximated quadratic cost:  99330\n",
      " Arc \t\t\t      Flow / Capacity \tprobability \tFee (sats)\n",
      "7899 -> 9097     \t  3350000 / 16777215 \t0.800324\t4478.950000\n",
      "5644 -> 952     \t  3300000 / 200000000 \t0.983500\t16501.000000\n",
      "388 -> 7647     \t  3300000 / 1000000000 \t0.996700\t990.000000\n",
      "7899 -> 388     \t  3300000 / 16777215 \t0.803305\t4412.100000\n",
      "7899 -> 6390     \t  3350000 / 16777215 \t0.800324\t4478.950000\n",
      "4687 -> 1662     \t  3350000 / 3900000000 \t0.999141\t4.350000\n",
      "13131 -> 5644     \t  3300000 / 200000000 \t0.983500\t412.501000\n",
      "9097 -> 10600     \t  3350000 / 500000000 \t0.993300\t418.751000\n",
      "7647 -> 13131     \t  3300000 / 500000000 \t0.993400\t8250.000000\n",
      "6390 -> 4687     \t  3350000 / 300000000 \t0.988833\t837.500000\n",
      "1662 -> 952     \t  3350000 / 200000000 \t0.983250\t10047.650000\n",
      "10600 -> 952     \t  3350000 / 100000000 \t0.966500\t7608.850000\n",
      "Probability of Flow:  0.4595639284629304\n",
      "Total fee: 58440.602, rate: 0.058 %\n",
      "arcs included:  12\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Instantiate a SimpleMinCostFlow solver.\n",
    "    min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n",
    "    \n",
    "    # Add each arc.\n",
    "    for arc in arcs:\n",
    "        min_cost_flow.AddArcWithCapacityAndUnitCost(arc[0], arc[1], arc[2],\n",
    "                                                    arc[3])\n",
    "\n",
    "    # Add node supply to 0 for all nodes\n",
    "    for i in id_to_node_key.keys():\n",
    "        min_cost_flow.SetNodeSupply(i, 0)\n",
    "    #add amount to sending node\n",
    "    min_cost_flow.SetNodeSupply(node_key_to_id[SRC],int(AMT/QUANTIZATION))\n",
    "    #add -amount to recipient nods\n",
    "    min_cost_flow.SetNodeSupply(node_key_to_id[DEST],-int(AMT/QUANTIZATION))\n",
    "    \n",
    "    \n",
    "    # Find the min cost flow.\n",
    "    print(\"Deliver {:4.2f} BTC from\".format(AMT/100./1000/1000), node_key_to_id[SRC],\n",
    "          \"to\", node_key_to_id[DEST])\n",
    "\n",
    "    #only put solver in time computation.\n",
    "    #building of the network can be done while channels are announced on gossip\n",
    "    #the arcs do in practise not change (unless one uses the uncertainty network but even that is cheap)\n",
    "    start = time.time()\n",
    "    status = min_cost_flow.Solve()\n",
    "    end = time.time()\n",
    "    print(\"Runtime of flow computation: {:4.2f} sec \".format(end-start))\n",
    "    \n",
    "    if status != min_cost_flow.OPTIMAL:\n",
    "        print('There was an issue with the min cost flow input.')\n",
    "        print(f'Status: {status}')\n",
    "        exit(1)\n",
    "    \n",
    "    \n",
    "    ##\n",
    "    # From here just printing of results\n",
    "    ##\n",
    "    \n",
    "    print('Minimum approximated quadratic cost: ', min_cost_flow.OptimalCost())\n",
    "    #print('')\n",
    "    print(' Arc \\t\\t\\t      Flow / Capacity \\tprobability \\tFee (sats)')\n",
    "    probability = 1\n",
    "    total_flow = {}\n",
    "    for i in range(min_cost_flow.NumArcs()):\n",
    "        if min_cost_flow.Flow(i) == 0:\n",
    "            continue\n",
    "        cost = min_cost_flow.Flow(i) * min_cost_flow.UnitCost(i)\n",
    "        src = min_cost_flow.Tail(i)\n",
    "        dest = min_cost_flow.Head(i)\n",
    "        flow = min_cost_flow.Flow(i)*QUANTIZATION\n",
    "        \n",
    "        key = str(src)+\":\"+str(dest)\n",
    "        if key in total_flow:\n",
    "            total_flow[key]=(src,dest,total_flow[key][2]+flow)\n",
    "        else:\n",
    "            total_flow[key]=(src,dest,flow)\n",
    "    \n",
    "    total_fee = 0\n",
    "    for k,value in total_flow.items():\n",
    "        src,dest,flow = value\n",
    "        u_prob=uniform_probability(flow,src,dest)\n",
    "        fee = fee_msat(flow,src,dest)\n",
    "        total_fee += fee/1000\n",
    "        print('%1s -> %1s     \\t  %3s / %3s \\t%3f\\t%3f' %\n",
    "              (src, dest,flow, channel_graph[src][dest], u_prob,fee / 1000))\n",
    "        #break\n",
    "        probability *= u_prob\n",
    "    print(\"Probability of Flow: \", probability)\n",
    "    print(\"Total fee: {}, rate: {:5.3f} %\".format(total_fee,total_fee/1000000))\n",
    "    print(\"arcs included: \", len(total_flow))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
